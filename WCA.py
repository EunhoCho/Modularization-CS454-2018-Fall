from graphviz import Digraph
from graphviz import Graph
from graphviz import Source
from graphviz import render
from pyparsing import Forward, Word, alphas, alphanums, nums, ZeroOrMore, Literal, Group, QuotedString
import sys
import pydot


# done - read .dot file(.gv)
# done - visualize graph
# done - calculate CF for a module
# done - apply WCA algorithm and generate initial clusters

def read_and_render(filename):  # return source
    a = Source.from_file(filename)
    # print(a.source)
    # a.render(filename, view=True)
    return a


def parser(dot, arrow):  # parse .dot file and generate dependency(A->B) list
    def parse_dot(dot):
        par1 = dot.source.split(";\n")
        par2 = []
        for i in par1:
            for j in i.split(" "):
                par2.append(j)
        return par2

    def parse_line(lines):
        # remove "\n"
        result = lines[:]
        num = result.count("")
        for i in range(num):
            result.remove("")
        return result

    def get_edges(data, arrow):  # arrow = " -- " or " -> "
        length = len(data)
        edges = []
        for i in range(length):
            if data[i] == arrow:
                edges.append([data[i - 1], data[i + 1]])
        return edges

    a = parse_dot(dot)
    b = parse_line(a)
    edges = get_edges(b, arrow)
    edges[-1][1] = '"not found"'
    return edges


def is_contain(List, element):
    if List.count(element) >= 1:
        return True
    else:
        return False


# ============Turbo MQ================#
# TurboMQ functions - CF, summation of CF(calculate_fitness) functions

def calculate_CF(cluster, edges):
    mu_i = 0
    e_ij = 0
    e_ji = 0

    for edge in edges:
        from_node = edge[0]
        to_node = edge[1]
        if is_contain(cluster, from_node):
            if is_contain(cluster, to_node):
                mu_i += 1
            else:
                e_ij += 1
        elif is_contain(cluster, to_node):
            e_ji += 1
    CF_i = mu_i / (mu_i + (e_ij + e_ji) / 2)
    return CF_i


def calculate_fitness(clusters, edges):
    TurboMQ = 0

    for cluster in clusters:
        names = []
        for node in cluster.get_nodes():
            names.append(node)

        TurboMQ += calculate_CF(names, edges)
    return TurboMQ


# ============Turbo MQ end================#

# ============Nodes and cluster functions================#
def find_nodes(edges):  # get node names from edge(dependency) information
    node_names = []
    for edge in edges:
        if not (is_contain(nodes, edge[0])):
            nodes.append(edge[0])
        if not (is_contain(nodes, edge[1])):
            nodes.append(edge[1])
    return node_names


class _node(object):  # node class
    name = ""
    _from_node = []
    _to_node = []
    _feature_vector = []  # each node(class) has own feature vector

    def __init__(self):
        self.name = ""
        self.from_node = []
        self.to_node = []
        self.feature_vector = []

    def get_name(self):
        return self.name

    def get_from_node(self):
        return self.from_node

    def get_to_node(self):
        return self.to_node

    def get_feature_vector(self):
        return self.feature_vector[:]

    def set_name(self, _input):
        self.name = _input

    def add_from_node(self, _input):
        self.from_node.append(_input)

    def add_to_node(self, _input):
        self.to_node.append(_input)

    def set_feature_vector(self, _input):
        self.feature_vector = _input[:]


class _cluster(object):  # cluster(= set of nodes) class
    _nodes = []
    _feature_vector = []  # each cluster has own feature vector generated by nodes' feature vector(f1+f2/n1+n2 term)

    def __init__(self):
        self.nodes = []
        self.feature_vector = []

    def get_nodes(self):
        return self.nodes[:]

    def get_feature_vector(self):
        return self.feature_vector[:]

    def add_node(self, _input):
        self.nodes.append(_input)

    def set_feature_vector(self, _input):
        self.feature_vector = _input[:]

    def copy(self):
        new = _cluster()
        new.nodes = self.nodes[:]
        new.feature_vector = self.feature_vector[:]
        return new


def make_nodes(edges, nodes_names):  # make 'nodes' list composed of node class
    nodes = []
    for node_name in node_names:  # for each 'node name', set name, from_node and to_node.
        node = _node()
        node.set_name(node_name)
        for edge in edges:
            from_node = edge[0]
            to_node = edge[1]
            if node_name == from_node:
                node.add_from_node(to_node)
            if node_name == to_node:
                node.add_to_node(from_node)
        nodes.append(node)
    return nodes


def make_dependency_graph(edges, nodes, node_names):  # make dependency graph using edge information
    MDG = []
    temp = []
    numofnodes = len(nodes)
    for i in range(numofnodes):
        temp.append(0)
    for i in range(numofnodes):
        MDG.append(temp[:])
    # MDG = zeros(nodes_num, nodes_num) (n x n matrix)

    for i in range(numofnodes):
        curr_node = nodes[i]
        from_node = curr_node.get_from_node()
        j = 0
        for node_name in node_names:
            if node_name in from_node:
                MDG[i][j] = 1
            else:
                MDG[i][j] = 0
            j += 1
    return MDG


def cluster_initialize(nodes):  # make initial cluster which contains all singleton nodes, and each node is considered as a single cluster
    clusters = []
    numofnodes = len(nodes)
    for i in range(numofnodes):
        cluster = _cluster()
        cluster.add_node(nodes[i].get_name())
        cluster.set_feature_vector(nodes[i].get_feature_vector())
        clusters.append(cluster)
    return clusters


def compare_similarity(clusters, nodes):  # compare two clusters in clusters list, and return two most similar clusters among all clusters.
    numofcluster = len(clusters)
    numofnodes = len(nodes)  # numofnodes = dimension of feature vector
    max_UENM = -1
    max_c1 = _cluster()
    max_c2 = _cluster()

    for i in range(numofcluster):  # for all two-cluster combinations
        for j in range(numofcluster):
            if i >= j:
                continue

            cluster1 = clusters[i].copy()
            cluster2 = clusters[j].copy()
            feature1 = cluster1.get_feature_vector()
            feature2 = cluster2.get_feature_vector()
            # use WCA_UENM value
            a = 0
            b = 0
            c = 0
            d = 0
            n = 0
            Ma = 0
            # get a,b,c,d,n,Ma
            for k in range(numofnodes):
                if feature1[k] > 0 and feature2[k] > 0:
                    a += 1
                    Ma += feature1[k] + feature2[k]
                if feature1[k] > 0 and feature2[k] == 0:
                    b += 1
                if feature1[k] == 0 and feature2[k] > 0:
                    c += 1
                if feature1[k] == 0 and feature2[k] == 0:
                    d += 1
            # calculate UENM
            n = a + b + c + d
            UENM = (0.5 * Ma) / ((0.5 * Ma) + b + c + n)
            # if new UENM is higher than origianal max_UENM, then update it
            if UENM > max_UENM:
                max_UENM = UENM
                max_c1 = clusters[i]
                max_c2 = clusters[j]
    # print("UENM= ",max_UENM)
    return [max_c1, max_c2]


def merge_cluster(c1, c2, clusters, nodes):  # merge two most-similar clusters into one cluster.
    clus = clusters[:]
    clus.remove(c1)
    clus.remove(c2)
    merged_cluster = _cluster()
    c1_nodes = c1.get_nodes()
    c2_nodes = c2.get_nodes()
    for node in c1_nodes:
        merged_cluster.add_node(node)
    for node in c2_nodes:
        merged_cluster.add_node(node)

    # get new c1+c2 feature vector
    numofnodes = len(nodes)  # numofnodes = dimension of feature vector
    feature_vector = []  # initialize  feature vector
    for i in range(numofnodes):  # make n dimeansional feature vector
        feature_vector.append(0)
    feature1 = c1.get_feature_vector()
    feature2 = c2.get_feature_vector()
    numnode1 = len(c1.get_nodes())
    numnode2 = len(c2.get_nodes())

    for i in range(numofnodes):
        feature_vector[i] = numnode1 * feature1[i] + numnode2 * feature2[i]
        feature_vector[i] /= (numnode1 + numnode2)
    merged_cluster.set_feature_vector(feature_vector)

    clus.append(merged_cluster)
    return clus


def applyWCA(clusters, nodes, edges):
    max_TurboMQ = 0
    max_clusters = []
    numofnodes = len(nodes)
    count = 0
    for i in range(numofnodes - 1):  # clustering
        [c1, c2] = compare_similarity(clusters, nodes)  # clusters중 가장 비슷한 2개의 cluster를 선택
        # print (c1.nodes)
        # print (c2.nodes)
        clusters = merge_cluster(c1, c2, clusters, nodes)  # c1,c2가 merge된 clusters를 return
        TurboMQ = calculate_fitness(clusters, edges)  # calculate TurboMQ of these clusters
        if TurboMQ > max_TurboMQ:
            max_TurboMQ = TurboMQ
            max_clusters = clusters[:]
            count = 0
        else:
            count += 1
        if count == 3:
            print("TurboMQ = ", TurboMQ)
            break
        print("TurboMQ = ", TurboMQ)
    return [max_TurboMQ, max_clusters]


# read .gv file(dot) and create graphs
dot_file = read_and_render('test/all.gv')
print(dot_file.source)

# get edge information and parse it
edges = parser(dot_file, "->")  # second argument should be "--" or "->" (depends on .dot file format)
print(edges)

# make nodes as a list of node classes
node_names = find_nodes(edges)
nodes = make_nodes(edges, node_names)

# make dependency graph
MDG = make_dependency_graph(edges, nodes, node_names)

# get feature vector using MDG
for i in range(len(nodes)):
    nodes[i].set_feature_vector(MDG[i])

# apply WCA algorithm
clusters = cluster_initialize(nodes)
[result_MQ, result_clusters] = applyWCA(clusters, nodes, edges)  # result of WCA algorithm

for c in result_clusters:  # print all clusters which are not singleton
    if 1 != len(c.get_nodes()):
        print(c.get_nodes())
"""
#calculate CF
cluster = ['"scaffold-hunter-2.6.3.jar"','"java.base"']
CF1 = calculate_CF(cluster,edges)
"""
